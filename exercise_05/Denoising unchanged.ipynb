{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "herbal-fruit",
   "metadata": {},
   "source": [
    "# Exercise 05 - Denoising (25 + 45 = 70 (+ 10))\n",
    "In the lecture you have learned that noise is inevitable in digital imaging. In the last exercise sheet you\n",
    "were asked to reduce noise in an image by averaging multiple shots of the same scene. However, averaging\n",
    "multiple images of moving objects/dynamic scenes under dim lighting conditions (think of a live concert,\n",
    "for example) is a delicate task. Also increasing the exposure time to gather more light is often not an option\n",
    "due to motion blur. As a result, there is only a very faint signal forming the image on the sensor.\n",
    "Using typical CCD or CMOS sensors, this signal can not be amplified without also amplifying noise.\n",
    "Hence, denoising is an important image processing task.  \n",
    "\n",
    "There is a big variety of algorithms that reduce noise from images in a post processing step. In this\n",
    "exercise you will first implement a measure to determine the Signal-to-Noise Ratio (SNR) in an image, given\n",
    "the noise-free ground truth image. You will also implement a very easy, yet effective filter to remove noise\n",
    "from an image, namely the so-called _Bilateral Filter_.  \n",
    "A more powerful approach is the _Non-Local Means Filter_. In the second part of the exercise you will be guided through a simple implementation of this filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-joining",
   "metadata": {},
   "source": [
    "## Examples\n",
    "Run the following cells to see a visualization of a ground truth and noisy image pair.  \n",
    "The noisy image is generated by adding gaussian noise. Feel free to try any other of the ground truth images for testing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-certificate",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from noise import add_gaussian_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-faith",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the ground truth image.\n",
    "ground_truth_image = imageio.imread(os.path.join(\"images\", \"dice.png\"))\n",
    "# Other images for testing.\n",
    "# ground_truth_image = imageio.imread(os.path.join(\"images\", \"tablet.tiff\"))\n",
    "# ground_truth_image = imageio.imread(os.path.join(\"images\", \"tablet_small.tiff\"))\n",
    "# ground_truth_image = imageio.imread(os.path.join(\"images\", \"flowers.png\"))\n",
    "# ground_truth_image = imageio.imread(os.path.join(\"images\", \"man.png\"))\n",
    "\n",
    "ground_truth_image = ground_truth_image.astype(np.float32) / 255.0\n",
    "\n",
    "# Add noise to the image.\n",
    "noisy_image = add_gaussian_noise(\n",
    "    ground_truth_image, mean=0, sigma=0.05, color=True\n",
    ")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=[8, 4])\n",
    "axs[0].imshow((ground_truth_image * 255).astype(np.uint8))\n",
    "axs[0].set_title(\"(a) Ground truth (noiseless) image\", y=-0.2)\n",
    "axs[1].imshow((noisy_image * 255).astype(np.uint8))\n",
    "axs[1].set_title(\"(b) Noisy image\", y=-0.2)\n",
    "\n",
    "for j in range(2):\n",
    "    axs[j].set_axis_off()\n",
    "fig.set\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-india",
   "metadata": {},
   "source": [
    "## 1. Simple Image Denoising\n",
    "### a) (2)\n",
    "As you heard in the lecture we can measure the noise in a signal using Mean Squared Error (MSE) and Peak Signal-to-Noise Ratio (PSNR) which is based on the MSE.  \n",
    "Compute both using the scikit implementation on the already loaded __ground_truth_image__ and __noisy_image__. (HINT: Scikit-image comes installed with your pipenv environment.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-generation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Todo import and call functions from scikit-image.\n",
    "mse_noisy_scikit = 0\n",
    "psnr_noisy_scikit = 0\n",
    "print(\"MSE scikit-image implementation: {}\".format(mse_noisy_scikit))\n",
    "print(\"PSNR scikit-image implementation: {}\".format(psnr_noisy_scikit))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-indiana",
   "metadata": {},
   "source": [
    "### b) (6)\n",
    "The best (and probably only) way to reduce variance of a measurement is to average over multiple samples. This works best if you have some time and the subject does not move. Let's try it.\n",
    "\n",
    "When executing the next cell you will load some images into an array images of shape [N, H, W, C] and some dark frames for the camera which are stored in an array dark_frames of shape [N, H, W, C] where N is the number of images, H, W the spatial dimensions and C the color channels.\n",
    "\n",
    "Calculate the average dark frame, the average image and use the obtained dark frame to improve the quality of the averaged image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading images from files\n",
    "dark_frames = []\n",
    "images = []\n",
    "dark_path = os.path.join(\"images\", \"dark\", \"{}.tiff\")\n",
    "imgs_path = os.path.join(\"images\", \"imgs\", \"{}.tiff\")\n",
    "for i in range(1, 17):\n",
    "    images.append(imageio.imread(imgs_path.format(i)).astype(np.float32) / 255)\n",
    "    dark_frames.append(imageio.imread(dark_path.format(i)).astype(np.float32) / 255)\n",
    "images = np.stack(images)\n",
    "dark_frames = np.stack(dark_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dark_frame = np.zeros_like(images[0])  # TODO\n",
    "avg_image = np.zeros_like(images[0])       # TODO\n",
    "improved_img = np.zeros_like(images[0])    # TODO\n",
    "\n",
    "# showing result\n",
    "fig, axs = plt.subplots(2, 2, figsize=[8, 4], sharex=\"all\", sharey=\"all\")\n",
    "for ax in axs:\n",
    "    for a in ax:\n",
    "        a.set_axis_off()\n",
    "axs[0][0].imshow(images[0])\n",
    "axs[0][0].set_title(\"images[0]\")\n",
    "axs[0][1].imshow(avg_dark_frame/np.max(avg_dark_frame))\n",
    "axs[0][1].set_title(\"avg dark frame (normalized)\")\n",
    "axs[1][0].imshow(avg_image)\n",
    "axs[1][0].set_title(\"avg image\")\n",
    "axs[1][1].imshow(np.clip(improved_img, 0, 1))\n",
    "axs[1][1].set_title(\"improved\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-question",
   "metadata": {},
   "source": [
    "### c) (2)\n",
    "Use a simple Gauss filter to remove noise from the noisy image and compare the PSNR value of\n",
    "the result with the PSNR value of the input image. You are allowed to use the filter operations that come with either _opencv_ or _scikit-image_ this time.  \n",
    "\n",
    "HINT: Display the filtered image to verify your results visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigma = 1\n",
    "# Todo: Apply a gaussian filter to the image.\n",
    "gaussian_filtered_image = np.zeros_like(noisy_image)\n",
    "\n",
    "# Todo: Compute the PSNR here.\n",
    "psnr_gauss = 0\n",
    "print(\"PSNR gauss filter: {}\".format(psnr_gauss))\n",
    "print(\"PSNR improvement: {}\".format(psnr_gauss - psnr_noisy_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-butler",
   "metadata": {},
   "source": [
    "### d) (15)\n",
    "Implement a function `bilateral_filter(img, sigma_s, sigma_r)` where __img__ is the noisy input image, __sigma_s__ the standard deviation for the spatial domain filter and __sigma_r__ is the standard deviation in the color domain.  \n",
    "Compare the result and PSNR with the result of the Gauss filter.\n",
    "\n",
    "HINT: You might want to use a progress bar to show the progress of the filter operation. You can use _tqdm_. You can implement your own Gaussian filter or use OpenCV, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_filter(img: np.ndarray, sigma_s: float, sigma_r: float) -> np.ndarray:\n",
    "    \"\"\"Todo\n",
    "    \n",
    "        Bilateral filter with sigma_s for the spatial gauss filtering and sigma_r\n",
    "        for the gauss filter in color space.\n",
    "        \n",
    "    Args:\n",
    "        img:\n",
    "            Input image to be filtered.\n",
    "        sigma_s:\n",
    "            Standard deviation for the kernel in the spatial domain.\n",
    "        sigma_r:\n",
    "            Standard deviation for the kernel in the color domain.\n",
    "    \n",
    "    Returns:\n",
    "        The filtered image as np array.\n",
    "    \"\"\"\n",
    "    \n",
    "    img_shape = img.shape\n",
    "    \n",
    "    # Initialize output.\n",
    "    out_img = np.zeros_like(img)\n",
    "            \n",
    "    return out_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bilateral filter and compare the PSNR.\n",
    "sigma_s = 2\n",
    "sigma_r = 0.15\n",
    "\n",
    "# Call your bilateral filter here.\n",
    "bilateral_filtered_image = bilateral_filter(noisy_image, sigma_s, sigma_r)\n",
    "# Todo: Compute the psnr here.\n",
    "psnr_bilateral = 0\n",
    "\n",
    "print(\"PSNR bilateral filter: {}\".format(psnr_bilateral))\n",
    "print(\"PSNR improvement: {}\".format(psnr_bilateral - psnr_noisy_scikit))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-might",
   "metadata": {},
   "source": [
    "## 2. Non-Local Means Filter\n",
    "With the Bilateral Filter you have implemented your first non-trivial filter for image denoising. In this\n",
    "exercise you will create a simple implementation of a more advanced denoising filter: The Non-Local\n",
    "Means Filter (NLM filter). We use the same functions as in Exercise 1 to compare the results of the\n",
    "NLM filter. The NLM filter can be vectorized and thus be implemented efficiently using numpy, however,\n",
    "the vectorization is rather complicated and obscures the individual steps of the algorithm. In contrast,\n",
    "our step-by-step implementation will operate pixel-wise and therefore be slow. You might want to load\n",
    "the small __ground_truth_image__ (tablet_small.tiff) above for debugging purposes.  \n",
    "\n",
    "Mathematically, the NLM filter can be formulated as:  \n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{x}(i) = \\frac{1}{C(i)}\\int_{\\Omega(i)}v(i)\\,w(i,j) \\, dj\\qquad\n",
    "    \\text{with} \\qquad\n",
    "    C(i) = \\int_{\\Omega(i)}w(i,j) \\, dj\n",
    "\\end{align}\n",
    "$$\n",
    "where $i$ is a pixel position, $\\hat{x}(i)$ the filter output color intensity at that position, $v(i)$ the unfiltered pixel value at position $i$, $w(i,j)$ a weighting function and $\\Omega(i)$ an area around pixel $i$, which is a subset of the entire image. Consequently, the filter output is a weighted average (mean) over the image patch $\\Omega(i)$. The weighting function $w(i,j)$ computes the similarity between the pixel $i$ and $j$. The similarity is computed by comparing\n",
    "a small patch around $i$ with a small patch around $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-vector",
   "metadata": {},
   "source": [
    "### a) (15)\n",
    "A crucial component of the NLM filter is the comparison of image patches.\n",
    "The similarity $w(i,j)$ between two image patches $P_i$ and $P_j$ centered respectively at $i$ and $j$ is defined as  \n",
    "        $$w(i,j)=e^{-\\frac{\\|P_i - P_j\\|^2}{2\\sigma^2}}$$. \n",
    "\n",
    "Implement a function `similarity_weight(patch1, patch2, sigma)` ($i$ would correspond to 1 and $j$ to 2 here) which returns the similarity between two given patches in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Todo\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-corruption",
   "metadata": {},
   "source": [
    "### b) (5 + 5 + 15 + 5)\n",
    "Now complete the `non_local_means_filter` function which takes the __search_r__, __similarity_r__ and, again, __sigma__ as input and output the filtered image.  \n",
    "1. The NLM filter considers small square-shaped patches around pixels to compute similarities between pixels. Extend the input image in such a way that even pixels on the border can be compared. (HINT: The radius of the patch is given by __similarity_r__.)\n",
    "2. For a pixel at position $p = (y, x)$ extract the patch for the similarity comparison with all other pixels in the search radius.\n",
    "3. Iterate over the pixels in the search radius around $p = (y, x)$ and compute the similarity of those pixels using the function from a). The pixel at position $p = (y, x)$ is also contained in this search window - however, it gets a special treatment. Instead of reporting the similarity 1 on that pixel we use the maximum similarity amongst all other pixels in the window to weight it. Use the similarity as a weight to compute the average pixel value and sum up all used weights.\n",
    "4. Compute the filtered pixel value and write it to the result image. It can happen that the similarity of all pixels in the search window was zero (horrible image or wrong parameters). In that case just copy the input pixel to the result. Otherwise, normalize the computed pixel average using the summed weights according to the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_local_means_filter(img: np.ndarray, search_r: int, similarity_r: int, sigma: float) -> np.ndarray:\n",
    "    \"\"\"Denoise the input using the Non Local Means algorithm.\n",
    "\n",
    "    Args:\n",
    "        img:\n",
    "            Noisy input image to be denoised.\n",
    "        search_r:\n",
    "            Defines the radius around each pixel to seach for similar\n",
    "            pixels. In theory this would be the entire image,\n",
    "            but for performance reasons we limit the search to a window.\n",
    "        similarity_r:\n",
    "            Radius of a patch around a pixel that is used to determine\n",
    "            the similarity to other pixels (patches are compared).\n",
    "        sigma:\n",
    "            Standard deviation for determining the similarity between\n",
    "            patches (used in SimilarityWeight).\n",
    "\n",
    "    Returns:\n",
    "        Denoised image as np array.\n",
    "    \"\"\"\n",
    "    # Allocate output.\n",
    "    out_img = np.zeros_like(img)\n",
    "\n",
    "    # 1. Pad the input image to enable similarity comparison patches at the borders.\n",
    "    # Todo\n",
    "\n",
    "\n",
    "    # Start of the main loop. Using a progress bar, again.\n",
    "    for y in tqdm(range(img.shape[0]), desc=\"NLM filtering\"):\n",
    "        for x in range(img.shape[1]):\n",
    "            # 2. Extract patch around the pixel (y, x) for comparison.\n",
    "            # This window is then used to calculate the similarity to all\n",
    "            # other pixels in the search radius around this pixel.\n",
    "\n",
    "            # Todo!\n",
    "\n",
    "            # 3. Iterate over all pixels in the search window. Be careful not to cross\n",
    "            # image boundaries.\n",
    "            # * Skip the loop if the current pixel is at position (y,x).\n",
    "            # * Else extract a similarity window around the pixel.\n",
    "            # * Use the similarity_weight function from a) to compute the weight of the pixel.\n",
    "            # * Add the weighted pixel value to the average pixel value (pixel_average)\n",
    "            #   and the weight to the total pixel weight (pixel_weight)\n",
    "            # * Keep track of the maximum weight that was found and use it to\n",
    "            #   weight the pixel (y, x) in the end (after the iteration).\n",
    "\n",
    "            pixel_average = np.zeros([1, 1, 3])\n",
    "            pixel_weight = 0\n",
    "            max_weight = 0\n",
    "            \n",
    "            # Todo...\n",
    "            \n",
    "            \n",
    "            # 4. Write the result into the output image.\n",
    "            \n",
    "            # Todo!\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the NLM filter and compare the PSNR.\n",
    "search_window_r = 10\n",
    "similarity_window_r = 3\n",
    "sigma = 0.1\n",
    "\n",
    "# Call your NLM implementation here.\n",
    "nlm_filtered_image = non_local_means_filter(noisy_image, search_window_r, similarity_window_r, sigma)\n",
    "# Todo: Compute PSNR here.\n",
    "psnr_nlm = 0\n",
    "\n",
    "print(\"PSNR NLM filter: {}\".format(psnr_nlm))\n",
    "print(\"PSNR improvement: {}\".format(psnr_nlm - psnr_noisy_scikit))\n",
    "\n",
    "# You might also want to check your output image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-paragraph",
   "metadata": {},
   "source": [
    "### c) (10) (Bonus)\n",
    "Compare the results to the methods from the first part of the exercise sheet.  \n",
    "Try to find good parameters for all three methods (Gauss, Bilateral, NLM) on one of the given images (in images folder - you can just uncomment any of the lines in the second cell of this notebook). Create images that show results for 3 different parameter settings and explain the impact of the parameters (in text). Also compare the PSNR values. Do they represent your visual impression of the reconstruction quality?  \n",
    "\n",
    "HINT: Donâ€™t rise the search and similarity window radii too much. Try figuring out the best $\\sigma$ values.\n",
    "\n",
    "Run the following cell to get an overview plot of all the denoising approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all results for comparison.\n",
    "# Also show difference images.\n",
    "\n",
    "grey = np.ones_like(noisy_image) * 0.5\n",
    "\n",
    "fig2, axs2 = plt.subplots(3, 3, figsize=[10, 8])\n",
    "axs2[0][0].imshow(ground_truth_image)\n",
    "axs2[0][0].set_title(\"Ground truth\", y=-0.2)\n",
    "axs2[0][1].imshow(noisy_image)\n",
    "axs2[0][1].set_title(\"Noisy image (PSNR {:2.3f})\".format(psnr_noisy_own), y=-0.2)\n",
    "axs2[0][2].imshow(grey + noisy_image - ground_truth_image)\n",
    "axs2[0][2].set_title(\"Only noise\", y=-0.2)\n",
    "\n",
    "axs2[1][0].imshow(gaussian_filtered_image)\n",
    "axs2[1][0].set_title(\"Gauss filter (PSNR {:2.3f})\".format(psnr_gauss), y=-0.2)\n",
    "axs2[1][1].imshow(bilateral_filtered_image)\n",
    "axs2[1][1].set_title(\"Bilateral filter (PSNR {:2.3f})\".format(psnr_bilateral), y=-0.2)\n",
    "axs2[1][2].imshow(nlm_filtered_image)\n",
    "axs2[1][2].set_title(\"NLM filter (PSNR {:2.3f})\".format(psnr_nlm), y=-0.2)\n",
    "\n",
    "axs2[2][0].imshow(np.clip(grey + gaussian_filtered_image - ground_truth_image, 0, 1))\n",
    "axs2[2][0].set_title(\"Noise - gauss\", y=-0.2)\n",
    "axs2[2][1].imshow(np.clip(grey + bilateral_filtered_image - ground_truth_image, 0, 1))\n",
    "axs2[2][1].set_title(\"Noise - bilateral\", y=-0.2)\n",
    "axs2[2][2].imshow(np.clip(grey + nlm_filtered_image - ground_truth_image, 0, 1))\n",
    "axs2[2][2].set_title(\"Noise - NLM\", y=-0.2)\n",
    "\n",
    "plt.rcParams.update({'axes.titlesize': 'small'})\n",
    "fig2.suptitle(\"Comparison of different Denoising Algorithms\")\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs2[i][j].set_axis_off()\n",
    "fig2.set\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-celebrity",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "Here is room for your answer.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
