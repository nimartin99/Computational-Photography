{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "grave-mapping",
   "metadata": {},
   "source": [
    "# Exercise 03 - Depth of Field (5+30+40+5+10+5=95 P)\n",
    "Camera optics and lens effects are usually neglected when implementing a simple raytracer, so all it produces are images that are completely in focus and free from lens aberrations, essentially assuming a perfect pinhole camera. This is something not achievable with a real camera and therefore not perceived as a photographic look. However, it is very easy to extract depth information from a raytracer which can be used to add a depth-of-field effect.\n",
    "\n",
    "In this exercise, you are going to create a synthetic Depth-of-Field (DoF) effect into a rendered picture of the famous Sponza Atrium in the Å ibenik cathedral. To do so, you are given two images: An all-in-focus image of the Atrium and the corresponding depth map, which holds the distance from lens to surface point for each pixel. In order to create a proper looking picture, you need to add some DoF blur to it.\n",
    "\n",
    "The __focal length__ of the lens, __radius__ of the lens __aperture__ and the __sensor size__ are provided in the given code-snippets. The desired __focusing distance__ is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-symphony",
   "metadata": {},
   "source": [
    "## Input and expected result\n",
    "If you execute the next two cells you'll get an overview of the input images (a) and (b), a correctly raytraced image with depth of field (c) and the expected result you should get at the end of this exercise (d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-temple",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from flt_reader import read_flt_image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-facility",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the images used to show the desired effect\n",
    "all_in_focus = imageio.imread(os.path.join(\"images\", \"sponza_normal.jpg\"))\n",
    "depth_image = imageio.imread(os.path.join(\"images\", \"sponza_depth.jpg\"))\n",
    "correct_raytraced_image = imageio.imread(os.path.join(\"images\", \"sponza_correct.jpg\"))\n",
    "expected_outcome = imageio.imread(os.path.join(\"images\", \"sponza_blurred.jpg\"))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=[8, 8])\n",
    "axs[0][0].imshow(all_in_focus)\n",
    "axs[0][0].set_title(\"(a) All-in-focus image\", y=-0.1)\n",
    "axs[0][1].imshow(depth_image)\n",
    "axs[0][1].set_title(\"(b) Depth image\", y=-0.1)\n",
    "axs[1][0].imshow(correct_raytraced_image)\n",
    "axs[1][0].set_title(\"(c) Correctly ray traced image\", y=-0.1)\n",
    "axs[1][1].imshow(expected_outcome)\n",
    "axs[1][1].set_title(\"(d) Blured image (expected outcome)\", y=-0.1)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axs[i][j].set_axis_off()\n",
    "fig.set\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The given camera parameters. You can play with the values, but make sure to set them back to the defaults before submitting!\n",
    "# lens focal length, default: 0.02625\n",
    "focal_length = 0.02625\n",
    "\n",
    "# aperture radius, default: 0.05\n",
    "aperture_radius = 0.05\n",
    "\n",
    "# sensor x,y dimensions (square sensor surface, aspect ratio = 1) default: 0.024\n",
    "sensor_size = 0.024\n",
    "\n",
    "# distance from lens to plane of focus, default: 1\n",
    "focus_distance = 1\n",
    "\n",
    "# pixel width, height\n",
    "pixel_size = sensor_size / all_in_focus.shape[0]\n",
    "\n",
    "## Floating point input images to work with\n",
    "all_in_focus = read_flt_image(os.path.join(\"images\", \"sponza_normal.flt\"))\n",
    "depth_image = read_flt_image(os.path.join(\"images\", \"sponza_depth.flt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-catalyst",
   "metadata": {},
   "source": [
    "### a) (5 P)\n",
    "Compute the distance from the lens plane to the image plane (distance between the lens and the sensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thin lens equation: 1/f = 1/z + 1/z'\n",
    "# for z = focus_distance we get the distance of the sensor to the lens\n",
    "sensor_distance = 1  # TODO: Compute sensor distance\n",
    "\n",
    "print(\"sensor_distance: {}\".format(sensor_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-keeping",
   "metadata": {},
   "source": [
    "### b) (30 P)\n",
    "For each pixel precompute the _circle of confusion_, which will be the radius of the blur kernel in the image plane (as a floating point value).\n",
    "Convert the radii into pixel-units.\n",
    "\n",
    "__HINT:__ This can be done without loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute the blur kernel radii for all pixels\n",
    "blur_radius = np.zeros_like(depth_image)  # TODO: compute the blur radius (circle of confusion)\n",
    "\n",
    "# precompute the blur size (in pixels) for all pixels - the value of blur_radius\n",
    "# in pixels\n",
    "blur_radius_pixel = blur_radius  # TODO: convert radii to pixel units\n",
    "\n",
    "\n",
    "# extract the maximum kernel size\n",
    "max_blur = int(np.ceil(np.max(blur_radius_pixel)))\n",
    "\n",
    "print(\"max_blur =\", max_blur)\n",
    "\n",
    "# show computed maps\n",
    "fig_blur_radius = plt.figure(figsize=(6, 6))\n",
    "ax = fig_blur_radius.add_subplot(111)\n",
    "m_plot = ax.imshow(blur_radius_pixel)\n",
    "ax.set_title(\"blur_radius\")\n",
    "ax.set_axis_off()\n",
    "fig_blur_radius.colorbar(m_plot, ax=ax)\n",
    "fig_blur_radius.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-habitat",
   "metadata": {},
   "source": [
    "The function `blur_kernel(radius)` generates a blur-kernel that contains a mask for a circle-of-confusion with the given _radius_. You can use this function for the next task.\n",
    "\n",
    "The figure created when executing the next cell gives you an impression on how the `blur_kernel` function behaves. A pixel is added to the kernel if at least half of its surface is within the circle defined by the radius. Feel free to experiment with different radii in the visualizations to see how they affect the kernels.\n",
    "\n",
    "_Note: Don't be confused by the [type-hints](https://www.python.org/dev/peps/pep-0484/) in `blur_kernel`, they are used in python to explain what type of input is expected and what type of output is returned. The functionality is not changed._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_kernel(radius: float) -> np.ndarray:\n",
    "    \"\"\"Generates a circular kernel for the given blur-radius.\n",
    "\n",
    "    The kernel always contains the center-pixel.\n",
    "\n",
    "    Args:\n",
    "        radius: Radius of the generated blur-kernel.\n",
    "    Returns:\n",
    "        A 2d-float-array, which contains 1 inside the radius (from the center) and 0 outside.\n",
    "    \"\"\"\n",
    "    radius = max(radius - 0.5, 1e-6)\n",
    "    line = np.linspace(np.floor(-radius), np.ceil(radius), 2 * int(np.ceil(radius)) + 1)\n",
    "    xs, ys = np.meshgrid(line, line)\n",
    "    points = np.stack([ys, xs], axis=-1)\n",
    "    distances = np.linalg.norm(np.stack([ys, xs], axis=-1), axis=-1)\n",
    "    mask = distances < radius\n",
    "    return mask.astype(np.float32)\n",
    "\n",
    "\n",
    "# plot some examples\n",
    "fig_pad = plt.figure(figsize=(8, 2))\n",
    "ax = fig_pad.add_subplot(141)\n",
    "ax.imshow(blur_kernel(128))\n",
    "\n",
    "ax.set_title(\"blur_kernel(128)\")\n",
    "ax = fig_pad.add_subplot(142)\n",
    "ax.imshow(blur_kernel(5.5))\n",
    "\n",
    "ax.set_title(\"blur_kernel(5.5)\")\n",
    "ax = fig_pad.add_subplot(143)\n",
    "ax.imshow(blur_kernel(5.6))\n",
    "\n",
    "ax.set_title(\"blur_kernel(5.6)\")\n",
    "ax = fig_pad.add_subplot(144)\n",
    "ax.imshow(blur_kernel(0))\n",
    "\n",
    "ax.set_title(\"blur_kernel(0)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-invasion",
   "metadata": {},
   "source": [
    "### c) 40 P\n",
    "Splat each pixel value to its neighbors and update the `accumulation_buffer` to keep track of how many values were splatted to every pixel.\n",
    "The splatting is to be performed using the given `blur_kernel` function for the blur-radius of each pixel.\n",
    "\n",
    "_Note:_ The `blurred_image` and `accumulation_buffer` are larger to allow splatting into the border areas. The relevant part is cropped out in the end.\n",
    "  Make sure to access those output arrays accordingly.\n",
    "\n",
    "_Info: [tqdm](https://github.com/tqdm/tqdm#tqdm) is responsible for the beautiful progress bar._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate the depth-blurred image and the accumulation buffer\n",
    "in_shape = all_in_focus.shape\n",
    "out_shape = (in_shape[0] + 2 * max_blur, in_shape[1] + 2 * max_blur, in_shape[2])\n",
    "blurred_image = np.zeros(out_shape, dtype=np.float32)\n",
    "accumulation_buffer = np.zeros([out_shape[0], out_shape[1]], dtype=np.float32)\n",
    "\n",
    "# Iterate over all all_in_focus pixels and splat them into the blurred image\n",
    "for y in tqdm(range(all_in_focus.shape[0])):\n",
    "    for x in range(all_in_focus.shape[0]):\n",
    "        # TODO: lookup the blur radius for the current pixel\n",
    "        pass  # TODO remove this.\n",
    "\n",
    "\n",
    "        # TODO: get the current blur kernel\n",
    "\n",
    "        # TODO: perform the splatting in image space\n",
    "\n",
    "        # TODO: update the accumulation buffer\n",
    "\n",
    "# cut out center\n",
    "blurred_image = blurred_image[max_blur:-max_blur, max_blur:-max_blur]\n",
    "accumulation_buffer = accumulation_buffer[max_blur:-max_blur, max_blur:-max_blur]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-custody",
   "metadata": {},
   "source": [
    "### d) (5 P)\n",
    "Finally normalize the blurred image using the `accumulation_buffer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image_normalized = np.zeros_like(all_in_focus)  # TODO normalize blurred image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-claim",
   "metadata": {},
   "source": [
    "### e) (10 P)\n",
    "Visually compare the result you obtained with the provided image which has been correctly ray traced using\n",
    "a thin lens model.\n",
    "\n",
    "What is the reason for the differences to the ray-traced version shown above? Could they be solved by changing the algorithm and how so?\n",
    "Write your answer as text into the given Markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-mumbai",
   "metadata": {},
   "source": [
    "TODO: Put your text answers here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a995ee6-b1f4-4baf-8411-e54e33ddf5b3",
   "metadata": {},
   "source": [
    "### f) (5 P)\n",
    "Now your image looks more like a photograph. Still some other aberrations are missing from the synthetic image.\n",
    "Name two aberrations that are easy to approximate in image space and explain how it could be implemented. There is no need to write any code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac86613-432d-4af0-aa82-960e7623e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: Put your text answers here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-tournament",
   "metadata": {},
   "source": [
    "## Links:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-jacob",
   "metadata": {},
   "source": [
    "Depth of field is nicely explained [here](http://www.cambridgeincolour.com/tutorials/depth-of-field.htm)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
